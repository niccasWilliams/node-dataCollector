# ğŸ”’ Onlogist Security & Anti-Detection Guide

## âš ï¸ SEHR WICHTIG - Vor dem ersten Test lesen!

Onlogist.com nutzt wahrscheinlich Bot-Detection. Daher ist **maximale Vorsicht** geboten!

## âœ… Anti-Detection MaÃŸnahmen (Implementiert)

### 1. **Patchright Browser**
- âœ… Verwendet **Patchright** statt Standard-Playwright
- âœ… Patcht CDP (Chrome DevTools Protocol) Leaks automatisch
- âœ… Entfernt `navigator.webdriver` Detection
- âœ… Umgeht Runtime.enable Detection

### 2. **Chrome Extensions** (NEU!)
- âœ… LÃ¤dt Dummy-Extension (macht Browser authentischer)
- âœ… Nutzt `launchPersistentContext` (erforderlich fÃ¼r Extensions)
- ğŸ“ Extension-Pfad: `extensions/dummy-extension/`

### 3. **Fingerprint Protection**
- âœ… WebRTC IP Leak Protection
- âœ… Canvas Fingerprinting Protection (Noise-Injection)
- âœ… Audio Context Protection
- âœ… WebGL Fingerprinting Protection
- âœ… Battery API entfernt
- âœ… Hardware Concurrency Randomization
- âœ… Device Memory Spoofing
- âœ… Plugins Spoofing
- âœ… Languages konsistent mit Locale

### 4. **Humanized Interactions**
- âœ… ZufÃ¤llige VerzÃ¶gerungen bei Klicks/Typing
- âœ… Realistische Mausbewegungen (Bezier-Kurven)
- âœ… Gelegentliche "Tippfehler"
- âœ… Variable Scroll-Geschwindigkeiten

### 5. **Session Management**
- âœ… Persistente User-Profile (sieht aus wie echter Browser)
- âœ… Cookie-Speicherung zwischen Sessions mÃ¶glich
- âœ… Separate Sessions pro Scrape (Isolation)

## ğŸ›¡ï¸ Nutzung des Stealth-Browsers fÃ¼r Onlogist

**WICHTIG:** Verwende IMMER den `BrowserStealthService` fÃ¼r Onlogist!

```typescript
import { browserStealthService } from '@/services/browser/browser-stealth.service';
import { onlogistService } from '@/services/onlogist';
import path from 'path';

// 1. Stealth-Session erstellen (mit Extension!)
const session = await browserStealthService.createStealthSession({
  headless: false, // Sichtbar zum Testen
  slowMo: 150, // Langsamer = menschlicher
  extensions: [
    path.join(__dirname, '../../../extensions/dummy-extension'),
  ],
});

// 2. Login durchfÃ¼hren
await onlogistService.login({
  username: process.env.ONLOGIST_USERNAME!,
  password: process.env.ONLOGIST_PASSWORD!,
});

// 3. AuftrÃ¤ge scrapen
const result = await onlogistService.searchOrders(session.id, {
  umkreis: 20,
  startort: "OsnabrÃ¼ck",
});

// 4. Session schlieÃŸen
await browserStealthService.closeSession(session.id);
```

## ğŸ­ ZusÃ¤tzliche SicherheitsmaÃŸnahmen

### Empfohlen:

1. **Proxy nutzen** (optional, aber empfohlen):
   ```typescript
   const session = await browserStealthService.createStealthSession({
     proxy: {
       server: 'http://proxy-server:port',
       username: 'user',
       password: 'pass',
     },
   });
   ```

2. **ZeitverzÃ¶gerungen** zwischen Aktionen:
   ```typescript
   // NICHT direkt hintereinander scrapen!
   await onlogistService.searchOrders(session.id, filters1);
   await new Promise(r => setTimeout(r, 5000 + Math.random() * 10000)); // 5-15 Sek
   await onlogistService.searchOrders(session.id, filters2);
   ```

3. **Verschiedene Suchfilter** (variieren):
   ```typescript
   // Nicht immer gleiche Filter!
   const filters = {
     umkreis: 15 + Math.floor(Math.random() * 10), // 15-25km
     startort: startOrte[Math.floor(Math.random() * startOrte.length)],
   };
   ```

### Optional (fÃ¼r maximale Paranoia):

4. **Session-Persistenz** (Login speichern):
   ```typescript
   // Beim ersten Login:
   const userDataDir = './chrome-profiles/onlogist-main';
   const session = await browserStealthService.createStealthSession({
     userDataDir, // Speichert Cookies/Login-State
   });
   // Bei nÃ¤chstem Start: Bereits eingeloggt!
   ```

5. **Manuelle Interaktion simulieren**:
   ```typescript
   // Nach Login: Kurz "herumsurfen"
   await session.page.mouse.move(400 + Math.random() * 200, 300 + Math.random() * 200);
   await session.page.waitForTimeout(2000);
   // Dann erst suchen
   ```

## âŒ NICHT TUN!

1. âŒ **Nicht zu schnell scrapen** (> 1x pro Minute ist verdÃ¤chtig)
2. âŒ **Nicht headless nutzen** (zumindest beim ersten Test)
3. âŒ **Nicht immer gleiche Filter** (variiere Suchparameter)
4. âŒ **Nicht parallele Sessions** vom gleichen Account
5. âŒ **Nicht ohne Extensions** (Browser ohne Extensions = Bot)
6. âŒ **Nicht Standard-BrowserService** (nutze IMMER BrowserStealthService!)

## ğŸ” Testing-Strategie (SICHER!)

### Phase 1: Manueller Test (MACH DAS ZUERST!)
```bash
# Starte Stealth-Browser, aber mache NICHTS automatisch
# Surfe manuell zu onlogist.com und logge dich ein
# PrÃ¼fe: Gibt es Warnungen? Captchas? VerdÃ¤chtige Nachrichten?
```

### Phase 2: Kontrolliertes Scraping
```typescript
// NUR 1-2 SuchvorgÃ¤nge pro Session!
// Mit langen Pausen (5+ Minuten) zwischen Sessions
```

### Phase 3: Production
```typescript
// Max. 10-20 Scrapes pro Tag
// Zeitlich variiert (nicht immer zur gleichen Zeit!)
// Verschiedene Filter nutzen
```

## ğŸ¯ Checkliste vor erstem Test

- [ ] `BrowserStealthService` statt `BrowserService` nutzen
- [ ] Extension in `extensions/dummy-extension/` vorhanden
- [ ] `headless: false` fÃ¼r ersten Test
- [ ] Credentials in `.env` oder `website_credentials` Tabelle
- [ ] Langsame Geschwindigkeit (`slowMo: 150+`)
- [ ] Keine parallelen Sessions
- [ ] Monitoring aktiviert (Logs beobachten)
- [ ] Notfall-Plan (was tun bei Detection?)

## ğŸš¨ Notfall: Was tun bei Detection?

Wenn Onlogist dich blockiert:

1. **Sofort stoppen** - Keine weiteren Versuche!
2. **IP wechseln** (Proxy, VPN, oder Router-Neustart)
3. **User-Profile lÃ¶schen** (`rm -rf chrome-profiles/*`)
4. **24h warten**
5. **Langsamere Strategie** (slowMo erhÃ¶hen, weniger Scrapes)

## ğŸ“Š Detection-Indikatoren

ğŸš¨ **SOFORT STOPPEN wenn:**
- Login schlÃ¤gt mehrmals fehl
- Captcha erscheint
- "VerdÃ¤chtige AktivitÃ¤t" Nachricht
- Account temporÃ¤r gesperrt
- Seite lÃ¤dt ungewÃ¶hnlich langsam

âš ï¸ **Vorsichtig sein wenn:**
- Seite verhÃ¤lt sich anders als sonst
- Neue Sicherheitsabfragen
- "Bot-Check" oder Ã¤hnliche Meldungen

## ğŸ’¡ Best Practices

1. **Start langsam:** Erst 1-2 Scrapes, dann Pause von Stunden/Tagen
2. **Timing variieren:** Nicht immer zur gleichen Uhrzeit
3. **Realistisches Verhalten:** Simuliere echte Nutzer-Aktionen
4. **Monitoring:** Logge ALLE Aktionen fÃ¼r spÃ¤tere Analyse
5. **Backup-Account:** Teste NIEMALS mit produktivem Account!

## ğŸ”— Weitere Ressourcen

- Patchright Docs: https://github.com/Kaliiiiiiiiii-Vinyzu/patchright
- Bot Detection Overview: https://blog.castle.io/anti-detect-frameworks
- WebRTC Leaks testen: https://browserleaks.com/webrtc
- Canvas Fingerprinting: https://browserleaks.com/canvas

---

**REMEMBER:** Langsam ist schnell! Ein erkannter Bot ist nutzlos.
Lieber 5 erfolgreiche Scrapes pro Tag als Account-Sperre.
